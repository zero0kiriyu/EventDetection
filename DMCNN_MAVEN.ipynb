{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revolutionary-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.vocab import Vectors\n",
    "from torch.nn import init\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torchtext.data import get_tokenizer\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "import jsonlines\n",
    "import json\n",
    "window_size=31\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitted-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LABEL = data.Field(sequential=False,use_vocab=False,is_target=True)\n",
    "TEXT = data.Field(fix_length=window_size,lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "increased-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "with jsonlines.open('maven/train.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        train += [obj]\n",
    "        \n",
    "test = []\n",
    "with jsonlines.open('maven/test.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        test += [obj]\n",
    "        \n",
    "dev = []\n",
    "with jsonlines.open('maven/valid.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        dev += [obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "boring-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = []\n",
    "# with jsonlines.open('DMCNN_MAVEN/train.jsonl') as reader:\n",
    "#     for obj in reader:\n",
    "#         train += [obj]\n",
    "        \n",
    "# test = []\n",
    "# with jsonlines.open('DMCNN_MAVEN/test.jsonl') as reader:\n",
    "#     for obj in reader:\n",
    "#         test += [obj]\n",
    "        \n",
    "# dev = []\n",
    "# with jsonlines.open('DMCNN_MAVEN/dev.jsonl') as reader:\n",
    "#     for obj in reader:\n",
    "#         dev += [obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "grand-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = dict()\n",
    "# for t in train:\n",
    "#     pre_c = count.get(t['label'],0)\n",
    "#     count[t['label']] = pre_c +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "brown-destruction",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 810,\n",
       " 2: 178,\n",
       " 3: 3145,\n",
       " 4: 662,\n",
       " 5: 2728,\n",
       " 6: 1236,\n",
       " 7: 417,\n",
       " 8: 153,\n",
       " 9: 772,\n",
       " 10: 2165,\n",
       " 11: 981,\n",
       " 12: 1176,\n",
       " 13: 1001,\n",
       " 14: 346,\n",
       " 15: 777,\n",
       " 16: 654,\n",
       " 0: 2001,\n",
       " 17: 283,\n",
       " 18: 242,\n",
       " 19: 2856,\n",
       " 20: 1625,\n",
       " 21: 1432,\n",
       " 22: 114,\n",
       " 23: 2920,\n",
       " 24: 891,\n",
       " 25: 453,\n",
       " 26: 793,\n",
       " 27: 275,\n",
       " 28: 505,\n",
       " 29: 1120,\n",
       " 30: 678,\n",
       " 31: 2628,\n",
       " 32: 258,\n",
       " 33: 459,\n",
       " 34: 1024,\n",
       " 35: 22,\n",
       " 36: 1392,\n",
       " 37: 903,\n",
       " 38: 203,\n",
       " 39: 626,\n",
       " 40: 620,\n",
       " 41: 911,\n",
       " 42: 554,\n",
       " 43: 764,\n",
       " 44: 350,\n",
       " 45: 1022,\n",
       " 46: 1282,\n",
       " 47: 103,\n",
       " 48: 97,\n",
       " 49: 225,\n",
       " 50: 709,\n",
       " 51: 520,\n",
       " 52: 199,\n",
       " 53: 504,\n",
       " 54: 677,\n",
       " 55: 350,\n",
       " 56: 104,\n",
       " 57: 124,\n",
       " 58: 842,\n",
       " 59: 251,\n",
       " 60: 936,\n",
       " 61: 1392,\n",
       " 62: 115,\n",
       " 63: 265,\n",
       " 64: 155,\n",
       " 65: 684,\n",
       " 66: 191,\n",
       " 67: 93,\n",
       " 68: 561,\n",
       " 69: 618,\n",
       " 70: 817,\n",
       " 71: 434,\n",
       " 72: 224,\n",
       " 73: 379,\n",
       " 74: 101,\n",
       " 75: 163,\n",
       " 76: 91,\n",
       " 77: 684,\n",
       " 78: 410,\n",
       " 79: 471,\n",
       " 80: 55,\n",
       " 81: 326,\n",
       " 82: 1653,\n",
       " 83: 57,\n",
       " 84: 2460,\n",
       " 85: 95,\n",
       " 86: 132,\n",
       " 87: 640,\n",
       " 88: 4,\n",
       " 89: 922,\n",
       " 90: 199,\n",
       " 91: 533,\n",
       " 92: 48,\n",
       " 93: 85,\n",
       " 94: 403,\n",
       " 95: 167,\n",
       " 96: 704,\n",
       " 97: 764,\n",
       " 98: 282,\n",
       " 99: 295,\n",
       " 100: 174,\n",
       " 101: 66,\n",
       " 102: 222,\n",
       " 103: 203,\n",
       " 104: 101,\n",
       " 105: 299,\n",
       " 106: 263,\n",
       " 107: 36,\n",
       " 108: 228,\n",
       " 109: 99,\n",
       " 110: 179,\n",
       " 111: 17,\n",
       " 112: 6,\n",
       " 113: 87,\n",
       " 114: 307,\n",
       " 115: 168,\n",
       " 116: 124,\n",
       " 117: 71,\n",
       " 118: 165,\n",
       " 119: 341,\n",
       " 120: 221,\n",
       " 121: 11,\n",
       " 122: 156,\n",
       " 123: 131,\n",
       " 124: 93,\n",
       " 125: 97,\n",
       " 126: 848,\n",
       " 127: 279,\n",
       " 128: 37,\n",
       " 129: 948,\n",
       " 130: 485,\n",
       " 131: 299,\n",
       " 132: 32,\n",
       " 133: 340,\n",
       " 134: 93,\n",
       " 135: 314,\n",
       " 136: 72,\n",
       " 137: 363,\n",
       " 138: 138,\n",
       " 139: 128,\n",
       " 140: 48,\n",
       " 141: 231,\n",
       " 142: 82,\n",
       " 143: 64,\n",
       " 144: 27,\n",
       " 145: 178,\n",
       " 146: 51,\n",
       " 147: 59,\n",
       " 148: 86,\n",
       " 149: 11,\n",
       " 150: 137,\n",
       " 151: 16,\n",
       " 152: 35,\n",
       " 153: 87,\n",
       " 154: 47,\n",
       " 155: 55,\n",
       " 156: 27,\n",
       " 157: 7,\n",
       " 158: 254,\n",
       " 159: 20,\n",
       " 160: 12,\n",
       " 161: 129,\n",
       " 162: 52,\n",
       " 163: 78,\n",
       " 164: 87,\n",
       " 165: 61,\n",
       " 166: 19,\n",
       " 167: 15,\n",
       " 168: 58}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "liked-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = []\n",
    "negative_c = 0\n",
    "for t in train:\n",
    "    content = t['content']\n",
    "    events = t['events']\n",
    "    negative_triggers = t['negative_triggers']\n",
    "    for event in events:\n",
    "        label = event['type_id']\n",
    "        for mention in event['mention']:\n",
    "            sentence = content[mention['sent_id']]\n",
    "            \n",
    "            trigger_first_token_index = mention['offset'][0]\n",
    "            left_index = max(0,trigger_first_token_index - int((window_size-1)/2))\n",
    "            right_index = trigger_first_token_index+int((window_size-1)/2) +1 #超过也没关系\n",
    "            \n",
    "            left_tokens = sentence['tokens'][left_index:trigger_first_token_index]\n",
    "            right_tokens = sentence['tokens'][trigger_first_token_index+1:right_index]\n",
    "            \n",
    "            token_half_len = int((window_size-1)/2)\n",
    "            left_pad_num=0\n",
    "            right_pad_num=0\n",
    "            if len(left_tokens)!=token_half_len:#需要padding\n",
    "                left_pad_num = token_half_len - len(left_tokens)\n",
    "            \n",
    "            if len(right_tokens)!=token_half_len:#需要padding\n",
    "                right_pad_num = token_half_len - len(right_tokens)    \n",
    "            \n",
    "            text_windows = [TEXT.pad_token] * left_pad_num + left_tokens \\\n",
    "                            + [sentence['tokens'][trigger_first_token_index]] \\\n",
    "                            + right_tokens + [TEXT.pad_token] * right_pad_num\n",
    "                    \n",
    "            if len(text_windows) != window_size:\n",
    "                print('error')\n",
    "            \n",
    "            train_dict += [{\n",
    "                'text':text_windows,\n",
    "                'label':label\n",
    "            }]\n",
    "    for negative_trigger in negative_triggers:\n",
    "        if negative_c >700:\n",
    "            break\n",
    "        sentence = content[negative_trigger['sent_id']]\n",
    "        \n",
    "        trigger_first_token_index = negative_trigger['offset'][0]\n",
    "        left_index = max(0,trigger_first_token_index - int((window_size-1)/2))\n",
    "        right_index = trigger_first_token_index+int((window_size-1)/2) +1 #超过也没关系\n",
    "\n",
    "        left_tokens = sentence['tokens'][left_index:trigger_first_token_index]\n",
    "        right_tokens = sentence['tokens'][trigger_first_token_index+1:right_index]\n",
    "\n",
    "        token_half_len = int((window_size-1)/2)\n",
    "        left_pad_num=0\n",
    "        right_pad_num=0\n",
    "        if len(left_tokens)!=token_half_len:#需要padding\n",
    "            left_pad_num = token_half_len - len(left_tokens)\n",
    "\n",
    "        if len(right_tokens)!=token_half_len:#需要padding\n",
    "            right_pad_num = token_half_len - len(right_tokens)    \n",
    "\n",
    "        text_windows = [TEXT.pad_token] * left_pad_num + left_tokens \\\n",
    "                        + [sentence['tokens'][trigger_first_token_index]] \\\n",
    "                        + right_tokens + [TEXT.pad_token] * right_pad_num\n",
    "\n",
    "        if len(text_windows) != window_size:\n",
    "            print('error')\n",
    "        negative_c +=1\n",
    "        train_dict += [{\n",
    "            'text':text_windows,\n",
    "            'label':0\n",
    "        }]\n",
    "\n",
    "    \n",
    "with jsonlines.open('DMCNN_MAVEN/train.jsonl', mode='w') as writer:\n",
    "    writer.write_all(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "prime-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dict = []\n",
    "negative_c = 0\n",
    "for t in dev:\n",
    "    content = t['content']\n",
    "    events = t['events']\n",
    "    negative_triggers = t['negative_triggers']\n",
    "    for event in events:\n",
    "        label = event['type_id']\n",
    "        for mention in event['mention']:\n",
    "            sentence = content[mention['sent_id']]\n",
    "            \n",
    "            trigger_first_token_index = mention['offset'][0]\n",
    "            left_index = max(0,trigger_first_token_index - int((window_size-1)/2))\n",
    "            right_index = trigger_first_token_index+int((window_size-1)/2) +1 #超过也没关系\n",
    "            \n",
    "            left_tokens = sentence['tokens'][left_index:trigger_first_token_index]\n",
    "            right_tokens = sentence['tokens'][trigger_first_token_index+1:right_index]\n",
    "            \n",
    "            token_half_len = int((window_size-1)/2)\n",
    "            left_pad_num=0\n",
    "            right_pad_num=0\n",
    "            if len(left_tokens)!=token_half_len:#需要padding\n",
    "                left_pad_num = token_half_len - len(left_tokens)\n",
    "            \n",
    "            if len(right_tokens)!=token_half_len:#需要padding\n",
    "                right_pad_num = token_half_len - len(right_tokens)    \n",
    "            \n",
    "            text_windows = [TEXT.pad_token] * left_pad_num + left_tokens \\\n",
    "                            + [sentence['tokens'][trigger_first_token_index]] \\\n",
    "                            + right_tokens + [TEXT.pad_token] * right_pad_num\n",
    "                    \n",
    "            if len(text_windows) != window_size:\n",
    "                print('error')\n",
    "            \n",
    "            dev_dict += [{\n",
    "                'text':text_windows,\n",
    "                'label':label\n",
    "            }]\n",
    "    for negative_trigger in negative_triggers:\n",
    "        if negative_c >700:\n",
    "            break\n",
    "        sentence = content[negative_trigger['sent_id']]\n",
    "        \n",
    "        trigger_first_token_index = negative_trigger['offset'][0]\n",
    "        left_index = max(0,trigger_first_token_index - int((window_size-1)/2))\n",
    "        right_index = trigger_first_token_index+int((window_size-1)/2) +1 #超过也没关系\n",
    "\n",
    "        left_tokens = sentence['tokens'][left_index:trigger_first_token_index]\n",
    "        right_tokens = sentence['tokens'][trigger_first_token_index+1:right_index]\n",
    "\n",
    "        token_half_len = int((window_size-1)/2)\n",
    "        left_pad_num=0\n",
    "        right_pad_num=0\n",
    "        if len(left_tokens)!=token_half_len:#需要padding\n",
    "            left_pad_num = token_half_len - len(left_tokens)\n",
    "\n",
    "        if len(right_tokens)!=token_half_len:#需要padding\n",
    "            right_pad_num = token_half_len - len(right_tokens)    \n",
    "\n",
    "        text_windows = [TEXT.pad_token] * left_pad_num + left_tokens \\\n",
    "                        + [sentence['tokens'][trigger_first_token_index]] \\\n",
    "                        + right_tokens + [TEXT.pad_token] * right_pad_num\n",
    "\n",
    "        if len(text_windows) != window_size:\n",
    "            print('error')\n",
    "        negative_c +=1\n",
    "        dev_dict += [{\n",
    "            'text':text_windows,\n",
    "            'label':0\n",
    "        }]\n",
    "    \n",
    "with jsonlines.open('DMCNN_MAVEN/dev.jsonl', mode='w') as writer:\n",
    "    writer.write_all(dev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "extended-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = []\n",
    "for t in test:\n",
    "    content = t['content']\n",
    "    candidates = t['candidates']\n",
    "    for candidate in candidates:\n",
    "        sentence = content[candidate['sent_id']]\n",
    "\n",
    "        trigger_first_token_index = candidate['offset'][0]\n",
    "        left_index = max(0,trigger_first_token_index - int((window_size-1)/2))\n",
    "        right_index = trigger_first_token_index+int((window_size-1)/2) +1 #超过也没关系\n",
    "\n",
    "        left_tokens = sentence['tokens'][left_index:trigger_first_token_index]\n",
    "        right_tokens = sentence['tokens'][trigger_first_token_index+1:right_index]\n",
    "\n",
    "        token_half_len = int((window_size-1)/2)\n",
    "        left_pad_num=0\n",
    "        right_pad_num=0\n",
    "        if len(left_tokens)!=token_half_len:#需要padding\n",
    "            left_pad_num = token_half_len - len(left_tokens)\n",
    "\n",
    "        if len(right_tokens)!=token_half_len:#需要padding\n",
    "            right_pad_num = token_half_len - len(right_tokens)    \n",
    "\n",
    "        text_windows = [TEXT.pad_token] * left_pad_num + left_tokens \\\n",
    "                        + [sentence['tokens'][trigger_first_token_index]] \\\n",
    "                        + right_tokens + [TEXT.pad_token] * right_pad_num\n",
    "\n",
    "        if len(text_windows) != window_size:\n",
    "            print('error')\n",
    "\n",
    "        test_dict += [{\n",
    "            'text':text_windows,\n",
    "            'label':0\n",
    "        }]\n",
    "\n",
    "\n",
    "    \n",
    "with jsonlines.open('DMCNN_MAVEN/test.jsonl', mode='w') as writer:\n",
    "    writer.write_all(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "working-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train,test,dev=data.TabularDataset.splits(\n",
    "    path=\"DMCNN_MAVEN\",train='train.jsonl',\n",
    "    test='test.jsonl',validation='dev.jsonl',\n",
    "    format='json',fields={\n",
    "        'text': ('text', TEXT),\n",
    "        'label': ('label', LABEL)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "transparent-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train,test,dev, vectors=GloVe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "loose-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings=TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "physical-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_iterator, test_iterator, dev_iterator = data.BucketIterator.splits(\n",
    "    (train, test, dev), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort=False,\n",
    "    device = DEVICE,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "still-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0) # (batch_size,seq_len,embed,size)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "wired-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Block(nn.Module):\n",
    "    def __init__(self,window_size,out_channel,kernel_size,embedding_dim,drop_out):\n",
    "        super(CNN_Block,self).__init__()\n",
    "        self.cnn = nn.Conv2d(in_channels=1,out_channels=out_channel,kernel_size=(kernel_size,embedding_dim),padding=(kernel_size-1,0))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop_out = nn.Dropout(p=drop_out)\n",
    "        self.maxpool1d = nn.MaxPool1d(window_size+kernel_size-1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        cnn_out = self.cnn(x).squeeze(dim=-1)\n",
    "        relu_out = self.relu(cnn_out)\n",
    "        drop_out_result = self.drop_out(relu_out)\n",
    "        return self.maxpool1d(drop_out_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "gorgeous-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMCNN(nn.Module):\n",
    "    def __init__(self,window_sizes,kernel_sizes,out_channel,pretrained_embeddings,drop_out,total_classes):\n",
    "        super(DMCNN, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
    "        self.position_encoding = PositionalEncoding(d_model = pretrained_embeddings.size(1),max_len=window_size)\n",
    "        \n",
    "        self.cnn_blocks = nn.ModuleList([\n",
    "            CNN_Block(window_size,\n",
    "                      out_channel,\n",
    "                      kernel_size,\n",
    "                      pretrained_embeddings.size(1),\n",
    "                      drop_out) for kernel_size in kernel_sizes\n",
    "        ])\n",
    "        self.drop_out = nn.Dropout(p=drop_out)\n",
    "        self.linear = nn.Linear(in_features=out_channel*len(kernel_sizes)+pretrained_embeddings.size(1),out_features=total_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        word_embedding = self.word_embedding(x) # (batch_size,win_size,embed_size)\n",
    "        position_encoding = self.position_encoding(word_embedding) # (batch_size,win_size,embed_size)\n",
    "        we_pe = position_encoding.unsqueeze(dim=1) # (batch_size,1,win_size,embed_size)\n",
    "        cnn_outs = []\n",
    "        for cnn_block in self.cnn_blocks:\n",
    "            cnn_outs += [cnn_block(we_pe)]\n",
    "        total_cnn_outs = torch.cat(cnn_outs,dim=2) # (batch_size,out_channel,1)\n",
    "        total_cnn_outs = total_cnn_outs.view(total_cnn_outs.size(0),-1) #(batch_size,out_channel * kernel number)\n",
    "        \n",
    "        #下面是论文中没有提到的trick，把cnn输出和前半段的embedding vector和在一起进linear层\n",
    "        total_cnn_outs = torch.cat((total_cnn_outs, word_embedding[:, int((window_size-1)/2)]), dim=-1)\n",
    "        \n",
    "        #print(total_cnn_outs.shape)\n",
    "        drop_out_result = self.drop_out(total_cnn_outs)\n",
    "        y = self.linear(drop_out_result)        \n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "friendly-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMCNN(\n",
       "  (word_embedding): Embedding(48971, 300)\n",
       "  (position_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (cnn_blocks): ModuleList(\n",
       "    (0): CNN_Block(\n",
       "      (cnn): Conv2d(1, 150, kernel_size=(2, 300), stride=(1, 1), padding=(1, 0))\n",
       "      (relu): ReLU()\n",
       "      (drop_out): Dropout(p=0.5, inplace=False)\n",
       "      (maxpool1d): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): CNN_Block(\n",
       "      (cnn): Conv2d(1, 150, kernel_size=(3, 300), stride=(1, 1), padding=(2, 0))\n",
       "      (relu): ReLU()\n",
       "      (drop_out): Dropout(p=0.5, inplace=False)\n",
       "      (maxpool1d): MaxPool1d(kernel_size=33, stride=33, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): CNN_Block(\n",
       "      (cnn): Conv2d(1, 150, kernel_size=(4, 300), stride=(1, 1), padding=(3, 0))\n",
       "      (relu): ReLU()\n",
       "      (drop_out): Dropout(p=0.5, inplace=False)\n",
       "      (maxpool1d): MaxPool1d(kernel_size=34, stride=34, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): CNN_Block(\n",
       "      (cnn): Conv2d(1, 150, kernel_size=(5, 300), stride=(1, 1), padding=(4, 0))\n",
       "      (relu): ReLU()\n",
       "      (drop_out): Dropout(p=0.5, inplace=False)\n",
       "      (maxpool1d): MaxPool1d(kernel_size=35, stride=35, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=900, out_features=169, bias=True)\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DMCNN(31,[2,3,4,5],150,pretrained_embeddings,0.5,169)\n",
    "model.to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "contained-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "adequate-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    correct = 0\n",
    "    for batch_idx,batch in enumerate(train_iterator):\n",
    "        \n",
    "        output = model(batch.text.t())\n",
    "        l = loss(output, batch.label)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predicted = torch.max(output.data,1)[1]\n",
    "        correct += (predicted == batch.label).sum()\n",
    "        \n",
    "    break\n",
    "    print('epoch %d, loss: %f, correct: %f' % (epoch, l.item(),float(correct)/float((batch_idx+1)*128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "brown-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 128])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "affecting-publication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  28,  49,   6,  20, 118,  10,  84,  90,  12,  26,   4,   4,   3,\n",
       "         26,  66,  13,  21,   3,  54,  87,  51,  28,  45,  97,  77,   9,   5,\n",
       "         81,  50,  31,  24,  41,  45,   3,  14,  43,  19,   6,  45,  15,  53,\n",
       "         77,  19, 102,  31,  45,  72, 131,  70, 103,  16,  52,   7, 126,  51,\n",
       "          0, 126, 106,  10, 126,  34,   3,   3, 104, 102,  10,  99,  58,  15,\n",
       "         77,  19,  40,  36,  20,  53,  54,  31,  84,  34,  39,  65,  31, 158,\n",
       "         48,  34,  99,  94,  97,  19,  13,  19,  52,   3,  41,  23,  41,  70,\n",
       "         84,   3,  87, 147,  37,  58,  84,  53,  37,   3,   3,  82,  24,  24,\n",
       "         46,  34,  84,  24,  46,  23,  82,  84,  23, 122,  21,  33,   3,  86,\n",
       "          4,  23], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-moldova",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "systematic-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.train(False)\n",
    "correct = 0\n",
    "l = torch.tensor([],device=DEVICE)\n",
    "o = torch.tensor([],device=DEVICE)\n",
    "for batch_idx,batch in enumerate(dev_iterator):\n",
    "    output = model(batch.text.t())\n",
    "    l = torch.cat([l,batch.label])\n",
    "    o = torch.cat([o,torch.max(output.data,1)[1]])\n",
    "    #predicted = torch.max(output.data,1)[1]\n",
    "    #correct += (predicted == batch.label).sum()\n",
    "\n",
    "#print('correct: %f' % (float(correct)/float((batch_idx+1)*128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "acceptable-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002739647045593597"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(o.cpu(),l.cpu(),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "comparable-buyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0017792928011289434"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(o.cpu(),l.cpu(),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "amazing-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005952380952380952"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(o.cpu(),l.cpu(),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-structure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
